---
title: "GroupB_Final"
author: "S.Carpenè, G.Fantuzzi, V.Nigam, M.Tallone, A.Valentinis"
date: "2024-02-14"
output:
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
  pdf_document:
    toc: yes
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries_and_utilities, echo=FALSE, warning=FALSE, message=FALSE}
# Loading the utilities for libraries, assessment and plots
source("markdown_utils.r")

# Eventual additional options
options(rgl.useNULL=TRUE)

# Loading the dataset for eda plots

# Set working directory as this directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))

# Load the dataset from the datasets/ folder
bank <- read.csv("./datasets/BankChurners.csv", sep = ",")

# ⚠️ Remove the first and last two columns as suggested in the README
bank <- bank[, -c(1, 22, 23)]

# ⚠️ Convert the Attrition_Flag column to a binary variable:
# - 0: Existing Customer
# - 1: Attrited Customer
bank$Attrition_Flag <- ifelse(bank$Attrition_Flag == "Attrited Customer", 1, 0)

# Convert all categorical variables to factors
bank$Gender <- as.factor(bank$Gender)
bank$Education_Level <- as.factor(bank$Education_Level)
bank$Marital_Status <- as.factor(bank$Marital_Status)
bank$Income_Category <- as.factor(bank$Income_Category)
bank$Card_Category <- as.factor(bank$Card_Category)

# FIlter numerical variables and categorical variables
bank_num <- bank[, sapply(bank, is.numeric)]
bank_cat <- bank[, sapply(bank, is.factor)]

# Bank Logistic dataset

# Load the dataset and pre-process it
bank_logistic <- read.csv("./datasets/BankChurners.csv", sep = ",")
bank_logistic <- bank_logistic[, -c(1, 3, 5, 6, 9, 10, 14, 16, 17, 21, 22, 23)]
bank_logistic$Attrition_Flag <- ifelse(bank_logistic$Attrition_Flag == "Attrited Customer", 1, 0)

# Convert all categorical variables to factors and reorder the levels
bank_logistic$Gender <- as.factor(bank_logistic$Gender)
bank_logistic$Marital_Status <- as.factor(bank_logistic$Marital_Status)
bank_logistic$Marital_Status <- forcats::fct_relevel(bank_logistic$Marital_Status,
                                            "Unknown",
                                            "Single",
                                            "Married",
                                            "Divorced")

# Changing the levels of Marital_Status in either married or not married
bank_logistic$Marital_Status <- fct_collapse(bank_logistic$Marital_Status,
                                    "Married" = c("Married"),
                                    "Not Married" = c("Divorced",
                                                      "Single",
                                                      "Unknown"))

bank_logistic$Income_Category <- as.factor(bank_logistic$Income_Category)
bank_logistic$Income_Category <- forcats::fct_relevel(bank_logistic$Income_Category,
                                             "Unknown",
                                             "Less than $40K",
                                             "$40K - $60K",
                                             "$60K - $80K",
                                             "$80K - $120K",
                                             "$120K +")

# Changing the levels of income category into a binary variable:
bank_logistic$Income_Category <- fct_collapse(bank_logistic$Income_Category,
                                     "Less than 120K" = c("Unknown",
                                                          "Less than $40K",
                                                          "$40K - $60K",
                                                          "$60K - $80K",
                                                          "$80K - $120K"),
                                     "More than 120K" = c("$120K +"))

# Override the Total_Trans_Amt variable with its log !!!
bank_logistic$Total_Trans_Amt <- log(bank_logistic$Total_Trans_Amt)

# Standardization (optional) all columns except response and categorical
bank_logistic[, -c(1, 2, 3, 4)] <- scale(bank_logistic[, -c(1, 2, 3, 4)])

# ROSE
bank_logistic_balanced<- ROSE(Attrition_Flag~.,data=bank_logistic,seed = 123)$data
```

# Problem statement and dataset

The `BankChurners` dataset contains information about a bank's costumers and their credit card usage. The dataset is available on the Kaggle website and it is used for a classification problem. The main goal is to predict the `Attrition_Flag` response variable, which basically explains whether a customer will churn or not. The dataset consist of 10127 observations and 21 variables.

# Data preparation and EDA (Exploratory Data Analysis)

With the exclusion of the first variable (`CLIENTNUM`), that is just an identification number, and the last two (`Naive_Bayes_Classifier...`) variables, the dataset contains 19 possible covariates to be used for prediction. Among these, there are 6 categorical variables and 13 numerical variables.

The `Attrition_Flag` variable is the response variable and it is a binary variable. As it's possible to see form the following barplot, the dataset is unbalanced, with only 16.07% of the observations being positive, i.e. a churned costumer, for the `Attrition_Flag` variable.

```{r attrition_flag_barplot, echo=FALSE, fig.width=8, fig.height=5}
p1 <- ggplot(bank, aes(x = as.factor(Attrition_Flag))) +
    geom_bar(aes(fill = as.factor(Attrition_Flag)), color = "#FFFFFF") +
    scale_fill_manual(values = c("royalblue", "#FF5733"),
                      name = "Attrition Flag:",
                      labels = c("Existing", "Attrited")) +
    geom_text(aes(label = after_stat(count),
                  y = after_stat(count)),
              stat = "count",
              vjust = -0.5,
              size = 10) +
    labs(x = "Attrition Flag", y = "Count") +
    ggtitle("Response variable: Attrition_Flag") +
    theme(legend.position = c(.85, .85),
          legend.background = element_rect(fill = "transparent"),
          legend.direction = "vertical",
          legend.title = element_text(size = 10),
          aspect.ratio = 1) +
    ylim(0, 10000)

p2 <- ggplot(bank_logistic_balanced, aes(x = as.factor(Attrition_Flag))) +
    geom_bar(aes(fill = as.factor(Attrition_Flag)), color = "#FFFFFF") +
    scale_fill_manual(values = c("royalblue", "#FF5733"),
                      name = "Attrition Flag:",
                      labels = c("Existing", "Attrited")) +
    geom_text(aes(label = after_stat(count),
                  y = after_stat(count)),
              stat = "count",
              vjust = -0.5,
              size = 10) +
    labs(x = "Attrition Flag", y = "Count") +
    ggtitle("Response variable: Attrition_Flag") +
    theme(legend.position = c(.85, .85),
          legend.background = element_rect(fill = "transparent"),
          legend.direction = "vertical",
          legend.title = element_text(size = 10),
          aspect.ratio = 1) +
    ylim(0, 10000)

p1 | p2
```

```{r,echo=FALSE}
cat("Proportion of attrited (original dataset):",
    sum(bank$Attrition_Flag==1)/sum(table(bank_logistic$Attrition_Flag))*100,"%")
cat("Proportion of attrited (ROSE):",
    sum(bank_logistic_balanced$Attrition_Flag==1)/sum(table(bank_logistic$Attrition_Flag))*100,"%")
```

To check for possible correlation between the variables, we computed the correlation matrix and we plotted it using a heatmap. The correlation matrix is the following:

<!-- ```{r correlation_matrix, echo=FALSE} -->
```{r correlation_matrix, message=FALSE, echo=FALSE, fig.width=10, fig.height=10}
# Compute the correlation matrix
corm <- bank_num |>
  corrr::correlate() |>
  corrr::shave(upper = FALSE)


# Pivot the matrix and fix the labels
corm <- corm |>
  tidyr::pivot_longer(
    cols = -term,
    names_to = "colname",
    values_to = "corr"
  ) |>
  dplyr::mutate(
    rowname = forcats::fct_inorder(term),
    colname = forcats::fct_inorder(colname),
    label = dplyr::if_else(is.na(corr), "", sprintf("%1.2f", corr))
  )

# Plot the correlation matrix
ggplot(corm, aes(rowname, fct_rev(colname),
                 fill = corr)) +
  geom_tile() +
  geom_text(aes(
    label = label,
    color = abs(corr) < .75
  )) +
  coord_fixed(expand = FALSE) +
  scale_color_manual(
    values = c("white", "black"),
    guide = "none"
  ) +
  scale_fill_distiller(
    palette = "RdYlBu", na.value = "white",
    direction = -1, limits = c(-1, 1),
    name = "Pearson\nCorrelation:"
  ) +
  labs(x = NULL, y = NULL) +
  theme(panel.border = element_rect(color = NA, fill = NA),
        legend.position = c(.85, .8),
        axis.text.x = element_text(angle = 50, vjust = 1, hjust = 1))
```

As it's possible to see from the first column, the majority of the variables are not highly correlated with the response variable, with the exception of the `Total_Trans_Ct` variable that has a correlation of 0.37. However, an important thing to notice is that the correlation matrix shows some variables that are highly correlated with each other. Among these we can highlight:

* the `Avg_Open_To_Buy` and `Credit_Limit` variables, which are totally correlated;
* the `Months_on_book` and `Customer_Age` variables, that are reasonably correlated with a correlation of 0.79: indeed one expects that the number of months a customer has been with the bank is related to the customer's age;
* the `Total_Trans_Amt` and `Total_Trans_Ct` variables, that show a correlation of 0.81;
* the `Total_Revolving_Bal` and `Avg_Utilization_Ratio` variables, that are also highly correlated with a correlation of 0.62.

Since both the `Total_Trans_Amt` and `Total_Trans_Ct` variables are highly correlated between each other but, contrairly to the other variables, also show a significant correlation with the response variable, it made sense to plot the two variables in the following scatter plot to check for possible patterns.

```{r transactions_scatterplot, echo=FALSE}
# Plot of Total_Trans_Ct vs Total_Trans_Amt
ggplot(bank, aes(x = log(Total_Trans_Amt), y = Total_Trans_Ct, color = as.factor(Attrition_Flag))) +
  geom_point(alpha = .5) +
  scale_color_manual(values = c("0" = "royalblue", "1" = "#FF5733"),
                     name = "Attrition Flag:",
                     labels = c("Existing", "Attrited")) +
  labs(x = "Total Transaction Amount", y = "Total Transaction Count") +
  theme(legend.position = c(.85, .15),
        legend.background = element_rect(fill = "transparent"),
        legend.title = element_text(size = 10),
        aspect.ratio = 1)
```

The scatter plot represents the total number of transactions (on the y axis) agains the logarithm of the total transaction amount (on the x axis). The plot is colored by the `Attrition_Flag` variable, and we can indeed visually confirm the correlation among the two variables. However we can also spot that the churned customers are more concentrated in the lower left part of the plot.\
This fact is also reflected in the distribution analysis of the two variables reported below.
  
```{r trans_amt_distribution, echo=FALSE, fig.width=8, fig.height=8}
plot_continuous(bank, Total_Trans_Amt, "Total Transaction Amount", "Amount", 1000)
```

```{r trans_ct_distribution, fig.width=8, fig.height=8}
# plot_discrete(bank, Total_Trans_Ct, "Total Transaction Count", "Count")
plot_continuous(bank, Total_Trans_Ct, "Total Transaction Count", "Count", 5)
```

# Models implementation

Different models has been built to predict the `Attrition_Flag` variable and are presented in this section.
In order to assess the model performance, different effectiveness metrics have been used. These have been computed both by fitting the model using all the observations in the dataset and also by performing a k-fold cross validation with $k=10$. The metrics used are the following:

* Accuracy
* AUC
* FPR (False Positive Rate)
* FNR (False Negative Rate)
* Confusion matrix (*only for a single static split*)

The Dummy classifier has been taken as a baseline for comparison.

## Logistic regression

The first model we build in the attempt of predicting the response variable has been a logistic regression model using the $logit$ link function.\
In the initial model we included all the covariates except those that had low correlation with the response variable. We further filtered the covariates selection by discarding the variables that had a $p-value$ higher than 0.05 in the `glm()` summary output, i.e. the variables that were not statistically significant in the prediction.\
Possible multicollinearity problems, especially among the variables that showed high correlation in the exploratory analysis, were checked by looking at the Variance Inflation Factor (VIF) of the covariates.\
The final model has been built using the following variables:

* `Gender`: the gender of the customer
* `Marital_Status`: the marital status of the customer
* `Income_Category`: the income category of the customer
* `Total_Relationship_Count`: the total number of products held by the customer
* `Months_Inactive_12_mon`: the number of months inactive in the last 12 months
* `Contacts_Count_12_mon`: the number of contacts in the last 12 months
* `Total_Revolving_Bal`: the total revolving balance on the credit card
* `Total_Trans_Amt`: the total transaction amount in the last 12 months
* `Total_Trans_Ct`: the total transaction count in the last 12 months
* `Total_Ct_Chng_Q4_Q1`: the change in transaction count from Q4 to Q1

Aditionally, looking at the data distribution it has been taken the logarihmic values of the `Total_Trans_Amt` variable. Moreover the `Marital_Status` variable has been converted into a binary variable, taking the levels "Married" and "Not Married" since this change helped improving the statitical significane of the variable in the final model. For the same reason, the variable `Income_Category` has also been converted into a binary variable, dividing the clients in two categories: those with an income less than 120K and those with an income more than 120K.\
Both these changes have significantly improved the model performance as portrayed by the metrics explained below. An ANOVA test has also been performed to check the significance of the model.


```{r logistic_model_build, echo=FALSE}
# Rebuiding and checking the model
simple_logistic_model <- learn_logistic(bank_logistic)

```

### Results on the original dataset

On the given dataset, the built logistic model summary is the following:

```{r logistic_model_summary}
summary(simple_logistic_model)
```

The results of the ANOVA test are the following:

```{r logistic_model_anova}
anova(simple_logistic_model, test = "Chisq")
```

As its possible to see all the contribute in decreasing the deviance of the model, and they are all statistically significant.\

For what concerns the effectiveness metrics, we measured the following results on the original dataset:

```{r logistic model_results, message=FALSE, warning=FALSE}
logistic_results <- assess_logistic(simple_logistic_model, bank_logistic)
```

And similar results for the k-fold cross validation:

```{r logistic_model_cv_results, message=FALSE, warning=FALSE}
cv_logistic(bank_logistic)
```

From the results we can clearly see that the model is overall performing well. The accuracy is consistently over $90\%$ on all the folds, but this is not too surprising given the unbalance nature of the dataset. Good values have however been reached for the AUC and the FPR, with the worst metric being the FNR which falls just below $50\%$. The AIC and BIC values are also very low, which is a good sign for the model.

### Results on the synthetic dataset (ROSE)

Let's apply *ROSE* package:
```{r}
bank_logistic_balanced<- ROSE(Attrition_Flag~.,data=bank_logistic,seed = 123)$data
```

Now we can learn a logistic regression model on the new balanced dataset:

```{r}
ROSE_logistic_model <- learn_logistic(bank_logistic_balanced)
```

For what concerns the effectiveness metrics on the static trai test split:

```{r, message=FALSE, warning=FALSE}
ROSE_logistic_results<- assess_logistic(ROSE_logistic_model, bank_logistic_balanced)
```

Instead, by computing a 10-fold CV:
```{r, message=FALSE, warning=FALSE}
cv_logistic(bank_logistic_balanced)
```
**Comment:** the accuracy of this model, as expected, is lower than one of the logistic model learnt on the unbalanced dataset. However, the difference with respect to the dummy classifier becomes definitely more evident. Regarding the AUC score, even its value is slightly lower than before, it still showcases how good is the fit of our model. The metric that really improves after applying ROSE is the FNR: the model learnt on the unbalanced dataset had an average FNR of 44.11%, while now it drops around 17.87%. Conversely, FPR increases from 3.02% to 17.85%, but since we don't know anything about the costs of the errors, we considered it better to have more balanced metrics for FPR and FNR.

## GAM/Splines
We also tried using a General Additive Model to predict the Attrition_Flag variable. At first we included all the variables in the model, using a spline approximation for all the non categorical variables, obtaining an accuracy of 96,42% (AUC 98.99%). 
Than we removed from the model the variables not statistically significant and we included as linear variables whose spline approximation has an expected degree of freedom minor or equal to 2 obtaining an accuracy of 96,46% (AUC 98.92%). 
The final model has been built using as linear:

* `Customer_Age`: customer age in years
* `Gender`: the gender of the customer
* `Dependent_count`: number of dependents
* `Marital_Status`: married, not married
* `Total_Relationship_Count`: the total number of products held by the customer
* `Months_Inactive_12_mon`: the number of months inactive in the last 12 months
* `Contacts_Count_12_mon`: the number of contacts in the last 12 months
* `Total_Revolving_Bal`: the total revolving balance on the credit card
* `Total_Amt_Chng_Q4_Q1`: change in transaction amount
* `Total_Trans_Amt`: the total transaction amount in the last 12 months
* `Total_Trans_Ct`: the total transaction count in the last 12 months
* `Total_Ct_Chng_Q4_Q1`: the change in transaction count from Q4 to Q1

As in the logistic regression model we converted `Months_Inactive_12_mon` to a categorical variable with 4 categories: 1,2,3,4+; and we took the logarithmic values of `Total_Trans_Amt`.

The assessment has been done using the same procedure as the logistic regression model: we performed a k-fold cross validation with k=10, and we used the same metrics.

```{r gam_model_build, echo=FALSE}
# Set working directory as this directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))

# Load the dataset and pre-process it
bank_gam <- read.csv("./datasets/BankChurners.csv", sep = ",")

# ⚠️ Remove the last two columns as suggested in the README
bank_gam <- bank_gam[, -c(22, 23)]

# ⚠️ Remove the first column as it is just an index
bank_gam <- bank_gam[, -1]

# ⚠️ Convert the Attrition_Flag column to a binary variable:
# - 0: Existing Customer
# - 1: Attrited Customer
bank_gam$Attrition_Flag <- ifelse(bank_gam$Attrition_Flag == "Attrited Customer", 1, 0)

# Convert all categorical variables to factors
bank_gam$Gender <- as.factor(bank_gam$Gender)

bank_gam$Income_Category <- fct_collapse(bank_gam$Income_Category,
                                     "Less than 120K" = c("Unknown",
                                                          "Less than $40K",
                                                          "$40K - $60K",
                                                          "$60K - $80K",
                                                          "$80K - $120K"),
                                     "More than 120K" = c("$120K +"))

# Chnanging the levels of Marital_Status in either married or not married
bank_gam$Marital_Status <- fct_collapse(bank_gam$Marital_Status,
                                    "Married" = c("Married"),
                                    "Not Married" = c("Divorced",
                                                      "Single",
                                                      "Unknown"))
# Converting Months_Inactive_12_mon to a factor
bank_gam$Months_Inactive_12_mon <- as.factor(bank_gam$Months_Inactive_12_mon)
levels(bank_gam$Months_Inactive_12_mon) <- c("0", "1", "2", "3", "4", "5", "6+")

# Joining together the levels after 4 months
bank_gam$Months_Inactive_12_mon <- fct_collapse(bank_gam$Months_Inactive_12_mon,
                                            "4+" = c("4", "5", "6+"))

bank_gam$Education_Level <- as.factor(bank_gam$Education_Level)
bank_gam$Marital_Status <- as.factor(bank_gam$Marital_Status)
bank_gam$Income_Category <- as.factor(bank_gam$Income_Category)
bank_gam$Card_Category <- as.factor(bank_gam$Card_Category)
bank_gam$Total_Trans_Amt <- log(bank_gam$Total_Trans_Amt)
```

### Results on the original dataset

The build gamfit model is:

```{r gam_model_summary}
gamfit<-learn_gam(bank_gam)
summary(gamfit)
```
Regarding the effectiveness metrics we obtained:

```{r gam model_results, message=FALSE, warning=FALSE}
gam_results <- assess_gam(gamfit, bank_gam)
```
And similar results for the k-fold cross validation:

```{r gam_model_cv_results, message=FALSE, warning=FALSE}
cv_gam(bank_gam)
```

### Results on the synthetic dataset (ROSE)

First of all, let's obtain the synthetic dataset:
```{r,message=FALSE, warning=FALSE}
bank_gam_balanced<- ROSE(Attrition_Flag~.,data=bank_gam,seed = 123)$data
```

Learning phase of the model:
```{r,message=FALSE, warning=FALSE}
ROSE_gamfit<-learn_gam(bank_gam_balanced)
```


```{r,message=FALSE, warning=FALSE}
ROSE_gam_results<- assess_gam(ROSE_gamfit, bank_gam_balanced)
```

```{r, message=FALSE, warning=FALSE}
cv_gam(bank_gam_balanced)
```

## Decision Trees ?

## Ensemble Methods

The last class of methods we used to model the `Attrition_Flag` variable is ensamble methods, in particular we focussed on AdaBoost and Random Forest.\
The first model we built is an AdaBoost model on the whole dataset, which on its own achieved some great results. Then we proceeded by removing the variables considered not statistically significant in more complex models like `GAM`. This slight modification didn't much modify the accuracy of the model, which is always on the order of about $\sim90\%$.\
The final model has been built using the following variables:

* `Gender`: the gender of the customer
* `Total_Relationship_Count`: the total number of products held by the customer
* `Months_Inactive_12_mon`: the number of months inactive in the last 12 months
* `Contacts_Count_12_mon`: the number of contacts in the last 12 months
* `Total_Revolving_Bal`: the total revolving balance on the credit card
* `Total_Trans_Amt`: the total transaction amount in the last 12 months
* `Total_Trans_Ct`: the total transaction count in the last 12 months
* `Total_Ct_Chng_Q4_Q1`: the change in transaction count from Q4 to Q1
* `Marital_Status`: the marital status of the customer
* `Income_Category`: the income category of the customer

The same pre-processing steps of the `GLM` model were performed, slightly modifying classes or taking logarithmic values and converting the `Months_Inactive_12_mon` variable to a factor.\
The effectiveness metrics used to assess the model are:

* Accuracy
* AUC
* FPR (False Positive Rate)
* FNR (False Negative Rate)
* Confusion matrix
* Variable importance

The dummy classifier has been taken as a baseline for comparison.

```{r ada_model_build, echo=FALSE}
setwd(dirname(rstudioapi::getSourceEditorContext()$path))

# Load the dataset and pre-process it
bank_ensamble <- read.csv("datasets/BankChurners.csv", sep = ",")
bank_ensamble <- bank_ensamble[, -c(1, 22, 23)]
#bank$Attrition_Flag <- ifelse(bank$Attrition_Flag == "Attrited Customer", 1, 0)
# Convert Attrition_Flag to a binary factor
bank_ensamble$Attrition_Flag <- factor(bank_ensamble$Attrition_Flag == "Attrited Customer", levels = c(FALSE, TRUE))

# If "Attrited Customer" is TRUE, it will be coded as 1, and other values will be coded as 0


# Convert all categorical variables to factors and reorder the levels
bank_ensamble$Gender <- as.factor(bank_ensamble$Gender)
bank_ensamble$Income_Category <- fct_collapse(bank_ensamble$Income_Category,
                                     "Less than 120K" = c("Unknown",
                                                          "Less than $40K",
                                                          "$40K - $60K",
                                                          "$60K - $80K",
                                                          "$80K - $120K"),
                                     "More than 120K" = c("$120K +"))

# Changing the levels of Marital_Status in either married or not married
bank_ensamble$Marital_Status <- fct_collapse(bank_ensamble$Marital_Status,
                                    "Married" = c("Married"),
                                    "Not Married" = c("Divorced",
                                                      "Single",
                                                      "Unknown"))
# Converting Months_Inactive_12_mon to a factor
bank_ensamble$Months_Inactive_12_mon <- as.factor(bank_ensamble$Months_Inactive_12_mon)
levels(bank_ensamble$Months_Inactive_12_mon) <- c("0", "1", "2", "3", "4", "5", "6+")

# Joining together the levels after 4 months
bank_ensamble$Months_Inactive_12_mon <- fct_collapse(bank_ensamble$Months_Inactive_12_mon,
                                            "4+" = c("4", "5", "6+"))

bank_ensamble$Education_Level <- as.factor(bank_ensamble$Education_Level)
bank_ensamble$Marital_Status <- as.factor(bank_ensamble$Marital_Status)
bank_ensamble$Income_Category <- as.factor(bank_ensamble$Income_Category)
bank_ensamble$Card_Category <- as.factor(bank_ensamble$Card_Category)
# Override the Total_Trans_Amt variable with its log !!!
bank_ensamble$Total_Trans_Amt <- log(bank_ensamble$Total_Trans_Amt)
bank_ensamble <- bank_ensamble[, -c(2, 4, 5, 8, 9, 13, 15, 16, 20)]

# Actual model building
set.seed(1234)
index <- createDataPartition(bank_ensamble$Attrition_Flag , p =0.8, list = FALSE)

train_bank_ensamble <- bank_ensamble[index,]
test_bank_ensamble <- bank_ensamble[-index,]
```

Learning phase:
```{r learning_boost_rf,message=FALSE,warning=FALSE}
boost_model <- learn_boost(train_bank_ensamble)
rf_model <- learn_rf(train_bank_ensamble)
```

### Results on the original dataset
A summary-like output of the model doesn't exist, but we can still assess the model performance using the metrics described above.

First we show the results relative to a single run of the model on the dataset:

```{r ada_model_summary,message=FALSE,warning=FALSE}
boost_results <- assess_boost(boost_model, test_bank_ensamble)
```

Then the results on a 10-fold cross validation:

```{r ada_model_cv_results,message=FALSE,warning=FALSE}
cv_boost_results <- cv_boost(bank_ensamble)
```

As we can see from these results, AdaBoost is performing pretty well, having a consistent accuracy of over $90\%$ and a good AUC score. The FPR and FNR are also very low, keeping them consistently under $20\%$. Not having an AIC or BIC-like score, we can't really compare the model to the previous ones, but the results on classification are much better than the ones above, in particular with respect to the simple logistic regression.\

Passing to Random Forest, we perform the same analysis:

```{r rf_model_summary,message=FALSE,warning=FALSE}
rf_results <- assess_rf(rf_model, test_bank_ensamble)
```

```{r rf_model_cv_results,message=FALSE,warning=FALSE}
cv_rf_results <- cv_rf(bank_ensamble)
```

The results are very similar to the ones of AdaBoost, with the only difference being a slightly lower accuracy and AUC score. The FPR and FNR are also very low, keeping them consistently under $20\%$. A consistent note should be pointed that on the fact that performing cross validation, the average FNR decreases to below $5\%$, demonstrating the adaptive power of Random Forest also on unbalanced data.\


### Results on the synthetic dataset (ROSE)

From `bank_ensamble` let's obtain a new (synthetic) dataset:

```{r,message=FALSE,warning=FALSE}
bank_ensamble_balanced<- ROSE(Attrition_Flag~.,data=bank_ensamble,seed = 123)$data
```

It is now splitted into a training and test set (to be consistent, we use the same seed used before)
```{r,message=FALSE,warning=FALSE}
set.seed(1234)
index <- createDataPartition(bank_ensamble_balanced$Attrition_Flag , p =0.8, list = FALSE)
train_bank_ensamble_balanced <- bank_ensamble_balanced[index,]
test_bank_ensamble_balanced <- bank_ensamble_balanced[-index,]
```

Learning phase:
```{r,message=FALSE,warning=FALSE}
ROSE_boost_model <- learn_boost(train_bank_ensamble_balanced)
ROSE_rf_model <- learn_rf(train_bank_ensamble_balanced)
```

Assessment with static train/test division:

```{r,message=FALSE,warning=FALSE}
assess_boost(ROSE_boost_model, test_bank_ensamble_balanced)
```

```{r,message=FALSE,warning=FALSE}
assess_rf(ROSE_rf_model, test_bank_ensamble_balanced)
```
    

Assessment with 10-fold cross validation:

```{r,message=FALSE,warning=FALSE}
cv_boost(bank_ensamble_balanced)
```

```{r,message=FALSE,warning=FALSE}
cv_rf(bank_ensamble_balanced)
```
  
# Interpretations/Conclusions

| Model | Accuracy | AUC | FPR | FNR | Interpretability |